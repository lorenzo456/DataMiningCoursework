{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gr_smpl = pd.read_csv(\"./datasets/x_train_gr_smpl.csv\", delimiter=\",\", dtype=np.uint8)\n",
    "y_train_smpl = pd.read_csv(\"./datasets/y_train_smpl.csv\", delimiter=\",\", dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing methods for the dataset\n",
    "\n",
    "def get_array_of_matrix(dataset):\n",
    "    array_of_images = []\n",
    "    for row in dataset:\n",
    "        row = np.asarray(row)\n",
    "        matrix = np.reshape(row, (48, 48))\n",
    "        array_of_images.append(matrix)\n",
    "    return array_of_images\n",
    "\n",
    "\n",
    "def crop_dataset(dataset, row, clmn):\n",
    "    copped_dataset = []\n",
    "    for image in dataset:\n",
    "        y, x = image.shape\n",
    "        first_x = x//2-(row//2)\n",
    "        first_y = y//2-(clmn//2)\n",
    "        copped_dataset.append(image[first_y:first_y + clmn, first_x:first_x + row])\n",
    "    return copped_dataset\n",
    "\n",
    "\n",
    "def reshape_dataset(dataset):\n",
    "    reshaped_dataset = []\n",
    "    for image in dataset:\n",
    "        image = cv.resize(image, (48, 48)) # un po' bruttino\n",
    "        image = image.flatten()\n",
    "        reshaped_dataset.append(image)\n",
    "    # reshaped_dataset = np.reshape(reshaped_dataset, (12660, 2304)) # un po' bruttino\n",
    "    return reshaped_dataset\n",
    "\n",
    "\n",
    "def apply_adaptive_threshold(dataset):\n",
    "    dataset_with_filter = []\n",
    "    for image in dataset:\n",
    "        image = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
    "        image = image.flatten()\n",
    "        dataset_with_filter.append(image)\n",
    "    dataset_with_filter = np.reshape(dataset_with_filter, (12660,2304))\n",
    "    return dataset_with_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.asmatrix(x_train_gr_smpl)\n",
    "aom_dataset = get_array_of_matrix(dataset)\n",
    "cropped_dataset = crop_dataset(aom_dataset, 40, 40)\n",
    "new_dataset = reshape_dataset(cropped_dataset)\n",
    "dataset1 = apply_adaptive_threshold(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.append(dataset1, y_train_smpl, axis=1)\n",
    "x = df[:, 0:1599]\n",
    "y = df[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=1, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm = GaussianMixture()\n",
    "gmm.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters found: 1\n"
     ]
    }
   ],
   "source": [
    "labels = gmm.predict(x)\n",
    "print(f\"Total clusters found: {len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with 10 n_components as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters found: 10\n"
     ]
    }
   ],
   "source": [
    "gmm1 = GaussianMixture(n_components=10)\n",
    "gmm1.fit(x)\n",
    "labels1 = gmm1.predict(x)\n",
    "print(f\"Total clusters found: {len(np.unique(labels1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 141    0  414    6   78    0  463  305    3    0]\n",
      " [ 319    0  350    9  177    1  480  521    3    0]\n",
      " [ 107    0   93    1   31    0   32  155    1    0]\n",
      " [  98    0    0    0  145  923    3  151    0    0]\n",
      " [ 274    2    1    6  252    2   36  309 1217    1]\n",
      " [  71  731    0    0   95    0    0  219    4 1040]\n",
      " [ 104    0    3  470  140    2   57    4    0    0]\n",
      " [ 108    0   48    5   24    0   13   36    6    0]\n",
      " [ 329    1   11  385  731    2   23  587    1    0]\n",
      " [  74    0    1   68  101    0    1   54    0    1]]\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.10      0.09      1410\n",
      "           1       0.00      0.00      0.00      1860\n",
      "           2       0.10      0.22      0.14       420\n",
      "           3       0.00      0.00      0.00      1320\n",
      "           4       0.14      0.12      0.13      2100\n",
      "           5       0.00      0.00      0.00      2160\n",
      "           6       0.05      0.07      0.06       780\n",
      "           7       0.02      0.15      0.03       240\n",
      "           8       0.00      0.00      0.00      2070\n",
      "           9       0.00      0.00      0.00       300\n",
      "\n",
      "   micro avg       0.05      0.05      0.05     12660\n",
      "   macro avg       0.04      0.07      0.05     12660\n",
      "weighted avg       0.04      0.05      0.04     12660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y,labels1))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y,labels1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data=df, index=None,columns=None,dtype=np.uint8, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\singh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dataframe.rename(columns ={1600:\"Label\"}, inplace =True) #Renaming the last column as \"Label\"\n",
    "scaler.fit(dataframe.drop(\"Label\", axis=1))# Fit the data to all columns except Labels\n",
    "scaled_features = scaler.transform(dataframe.drop(\"Label\", axis=1))\n",
    "df_feat = pd.DataFrame(scaled_features,columns=dataframe.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12660 entries, 0 to 12659\n",
      "Columns: 2304 entries, 0 to 2303\n",
      "dtypes: float64(2304)\n",
      "memory usage: 222.5 MB\n"
     ]
    }
   ],
   "source": [
    "X = df_feat\n",
    "y = dataframe[\"Label\"]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters found: 1\n"
     ]
    }
   ],
   "source": [
    "gmm_scaled = GaussianMixture()\n",
    "gmm_scaled.fit(X)\n",
    "labels_scaled = gmm_scaled.predict(X)\n",
    "print(f\"Total clusters found: {len(np.unique(labels_scaled))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
